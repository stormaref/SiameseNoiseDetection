{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTPairs(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.pairs = list(itertools.combinations(range(len(self.dataset)), 2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx1, idx2 = self.pairs[idx]\n",
    "        img1, label1 = self.dataset[idx1]\n",
    "        img2, label2 = self.dataset[idx2]\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "        label = int(label1 == label2)\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        base_model = models.densenet121(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Linear(1024, 128)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.feature_extractor(input1)\n",
    "        output1 = self.fc(output1.view(output1.size(0), -1))\n",
    "        output2 = self.feature_extractor(input2)\n",
    "        output2 = self.fc(output2.view(output2.size(0), -1))\n",
    "        return output1, output2\n",
    "\n",
    "    def extract_features(self, input):\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(input)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                          (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, dataloader, device):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            for img1, img2, label in self.dataloader:\n",
    "                img1, img2, label = img1.to(self.device), img2.to(self.device), label.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output1, output2 = self.model(img1, img2)\n",
    "                loss = self.criterion(output1, output2, label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(self.dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVisualizer:\n",
    "    def __init__(self, model, dataloader, device):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def extract_embeddings(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for img, _, label in self.dataloader:\n",
    "                img = img.to(self.device)\n",
    "                embedding = self.model.extract_features(img)\n",
    "                embeddings.append(embedding.cpu().numpy())\n",
    "                labels.append(label.cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0)\n",
    "        return embeddings, labels\n",
    "    \n",
    "    def visualize(self, embeddings, labels):\n",
    "        tsne = TSNE(n_components=2)\n",
    "        tsne_results = tsne.fit_transform(embeddings)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.title('t-SNE visualization of image embeddings')\n",
    "        plt.xlabel('Dimension 1')\n",
    "        plt.ylabel('Dimension 2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Tester:\n",
    "    def __init__(self, model, dataloader, device):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def test(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for img1, img2, label in self.dataloader:\n",
    "                img1, img2, label = img1.to(self.device), img2.to(self.device), label.to(self.device)\n",
    "                output1, output2 = self.model(img1, img2)\n",
    "                euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "                predictions = (euclidean_distance < 0.5).float()\n",
    "                \n",
    "                all_labels.extend(label.cpu().numpy())\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        precision = precision_score(all_labels, all_predictions)\n",
    "        recall = recall_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Test Precision: {precision:.2f}\")\n",
    "        print(f\"Test Recall: {recall:.2f}\")\n",
    "        print(f\"Test F1 Score: {f1:.2f}\")\n",
    "\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using device:', device)\n",
    "# Load Fashion MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "train_pairs_dataset = FashionMNISTPairs(train_dataset)\n",
    "test_pairs_dataset = FashionMNISTPairs(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_pairs_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_pairs_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SiameseNetwork()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, device)\n",
    "trainer.train(num_epochs=10)\n",
    "\n",
    "# Test the model\n",
    "tester = Tester(model, test_loader, device)\n",
    "tester.test()\n",
    "\n",
    "# Visualize embeddings\n",
    "visualizer = EmbeddingVisualizer(model, test_loader, device)\n",
    "embeddings, labels = visualizer.extract_embeddings()\n",
    "visualizer.visualize(embeddings, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
